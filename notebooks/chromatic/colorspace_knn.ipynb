{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import skimage\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skimage.color import convert_colorspace\n",
    "from enum import Enum\n",
    "import re\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "from constants import BOW_TRAIN_PATH, BOW_TEST_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass(Enum):\n",
    "    NORMAL = 0\n",
    "    SMOKE = 1\n",
    "    FIRE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_class(path: str) -> DataClass:\n",
    "    regex = re.compile(\"([a-zA-Z_]+)([0-9]+)\")\n",
    "    match = regex.match(path)\n",
    "    if not match:\n",
    "        raise Exception(\"Invalid path: \" + path)\n",
    "\n",
    "    data_class = match.group(1)\n",
    "    if data_class == \"fire\":\n",
    "        return DataClass.FIRE\n",
    "    elif data_class == \"smoke\":\n",
    "        return DataClass.SMOKE\n",
    "\n",
    "    return DataClass.NORMAL\n",
    "\n",
    "\n",
    "def prepare_features(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for image_path in images:\n",
    "        image = skimage.io.imread(path + image_path)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # Convert to YCbCr\n",
    "        image_ycbcr = convert_colorspace(image, \"RGB\", \"YCbCr\")\n",
    "\n",
    "        # Prepare pixel values\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                X.append(image_ycbcr[i, j, :])\n",
    "                y.append(data_class(image_path).value)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train(path: str) -> GaussianNB:\n",
    "    model = GaussianNB()\n",
    "    X, y = prepare_features(path)\n",
    "    model.fit(X, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(model: GaussianNB, image: np.ndarray) -> np.ndarray:\n",
    "    height, width, _ = image.shape\n",
    "    image_ycbcr = convert_colorspace(image, \"RGB\", \"YCbCr\")\n",
    "    prediction = np.array(model.predict(image_ycbcr.reshape(-1, 3)))\n",
    "    mask = prediction.reshape(height, width)\n",
    "    mask = np.array(mask/2, dtype=int)\n",
    "    mask = np.array([mask, mask, mask])\n",
    "    mask = np.swapaxes(mask, 0, 2)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    return mask\n",
    "\n",
    "def test(model: GaussianNB, path: str, threshold: float = 0.15) -> int:\n",
    "    images = os.listdir(path)\n",
    "    correct = 0\n",
    "\n",
    "    for image_path in images:\n",
    "        image = skimage.io.imread(path + image_path)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        mask = generate_mask(model, image)\n",
    "        output_image = np.array(image)\n",
    "        output_image[mask == 0] = 0\n",
    "        \n",
    "        img_out_name = image_path[:-4] + '_out' + image_path[-4:] \n",
    "        img_save_path = os.path.join('/Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace', img_out_name)\n",
    "        skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
    "\n",
    "        is_fire = mask.sum() /height / width > threshold\n",
    "        actual = data_class(image_path)\n",
    "        \n",
    "        if actual == DataClass.FIRE and is_fire:\n",
    "            correct += 1\n",
    "        elif (actual == DataClass.SMOKE or actual == DataClass.NORMAL) and not is_fire:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(images)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(BOW_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire026_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire024_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire019_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/fire064_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire021_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/fire104_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/fire111_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire020_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire085_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire081_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire094_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire097_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/fire005_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire105_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire104_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire103_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire102_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire048_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire006_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire005_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire014_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n",
      "/var/folders/dy/7cnns26d2j52cnsqr1ms5fpm0000gn/T/ipykernel_86683/2981107611.py:26: UserWarning: /Users/tanmayk/Study/Cranfield - AI/IRP/aGANi/data/processed/colorspace/not_fire015_out.png is a low contrast image\n",
      "  skimage.io.imsave(img_save_path, output_image.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "accuracy = test(model, BOW_TEST_PATH)\n",
    "print('accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('IRP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4d666f55b8b5e68a52131f16bef3d80fcd0fee628049bb1bbc23cfcaa36fa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
